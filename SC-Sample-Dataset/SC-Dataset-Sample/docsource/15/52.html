<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<title>011-03-11 00:15:09,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Del - Pastebin.com</title>
		<link rel="shortcut icon" href="/favicon.ico" />
<link href="/cache/css/text.css" rel="stylesheet" type="text/css" />		<link href="/i/main.css" rel="stylesheet" type="text/css" />
				
		<script type="text/javascript" src="/js/jquery.js"></script>
		<script type="text/javascript" src="/js/main_v1.js"></script>
		<meta property="fb:app_id" content="231493360234820" />
		<meta property="og:title" content="011-03-11 00:15:09,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Del - Pastebin.com" />
		<meta property="og:type" content="article" />
	    <meta property="og:url" content="http://pastebin.com/zHrhU6yF" />
	    <meta property="og:image" content="http://pastebin.com/i/fb2.jpg" />
	    <meta property="og:site_name" content="Pastebin" />
		<meta name="google-site-verification" content="jkUAIOE8owUXu8UXIhRLB9oHJsWBfOgJbZzncqHoF4A" />
		<link rel="canonical" href="http://pastebin.com/zHrhU6yF" />
				<!--[if SafMob]>
			<style>body{-webkit-text-size-adjust:none;}</style>
		<![endif]-->
		<script type="text/javascript">
		  var _gaq = _gaq || [];
		  _gaq.push(['_setAccount', 'UA-58643-34']);
		  _gaq.push(['_trackPageview']);
			setTimeout("_gaq.push(['_trackEvent', '15_seconds', 'read'])", 15000);
		  (function() {
		    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
		    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
		    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		  })();
		</script>
	</head>
	<body>
	<div id="super_frame">
		<div id="logo" onclick="location.href='/'" title="Create New Paste"></div>
		<div id="header">
			<div id="header_top">
				<span class="span_left more">PASTEBIN</span><span class="span_left less"> &nbsp;|&nbsp; #1 paste tool since 2002</span><span class="min_max_span narrow_it" title="Change layout width"></span><span class="min_max_span wide_it" style="display:none" title="Change layout width"></span>				<ul class="top_menu">
					<li class="no_border_li"><a href="/" accesskey="n">create new paste</a></li><li><a href="/tools">tools</a></li><li><a href="/api">api</a></li><li><a href="/archive">archive</a></li><li><a href="/faq">faq</a></li>
				</ul>
			</div>
			<div id="header_middle">
				<span class="span_left big"><a href="/">PASTEBIN</a></span> 
				<a href="http://twitter.com/pastebin" target="_blank"><img src="/i/t.gif" alt="" class="i_tf" width="122" height="20" border="0" /></a>	<iframe src="//www.facebook.com/plugins/like.php?href=http%3A%2F%2Fwww.facebook.com%2Fpastebin&amp;send=false&amp;layout=button_count&amp;width=100&amp;show_faces=false&amp;action=like&amp;colorscheme=light&amp;font=segoe+ui&amp;height=21&amp;appId=231493360234820" scrolling="no" frameborder="0" style="border:none; overflow:hidden; width:100px; height:21px;margin:13px 0 0 10px;vertical-align:top" allowTransparency="true"></iframe>
				<div id="header_middle_search">
					<form class="search_form" name="search_form" method="get" action="/search" id="cse-search-box">
					    <input type="hidden" name="cx" value="partner-pub-7089230323117142:2864958357" />
					    <input type="hidden" name="cof" value="FORID:10" />
					    <input type="hidden" name="ie" value="UTF-8" />
						<input class="search_input" type="text" name="q" size="5" value="" placeholder="search..." x-webkit-speech/><input name="sa" class="search_button" src="/i/t.gif" alt="Search..." type="image" value="Search" />
					</form>
				</div>					
			</div>
			<div id="header_bottom">
				<div class="div_top_menu">
					<img src="/i/t.gif" class="i_n" width="16" height="16" alt="" border="0" /> <a href="/">create new paste</a> 
					&nbsp;&nbsp;&nbsp; <img src="/i/t.gif" class="i_t" width="16" height="16" alt="" border="0" /> <a href="/trends">trending pastes</a>
				</div>
				<ul class="top_menu">
					<li class="no_border_li"><a href="/signup">sign up</a></li><li><a href="/login">login</a></li><li><a href="/alerts">my alerts</a></li><li><a href="/settings">my settings</a></li><li><a href="/profile">my profile</a></li>				</ul>		
			</div>			
		</div>

			<div class="frame_spacer"><!-- --></div>
			<div style="height:35px;line-height:35px;font-size:0.85em;"><img src="/i/tip.png" width="16" height="16" style="vertical-align:middle;margin:-6px 0 0 2px" alt="" /> Pastebin launched a little side project called <a href="http://hostcabi.net/" target="_blank">HostCabi.net</a>, check it out ;-)<span style="float:right;text-align:right;">Don't like ads? <a href="/pro">PRO users</a> don't see any ads ;-)</span></div>		<div class="frame_spacer"><!-- --></div>
		<div id="monster_frame">
			<div id="content_frame">
				<div id="content_right">
										<div class="content_right_menu">
									<div class="content_right_title"><a href="/archive">Public Pastes</a></div>	
									<div id="menu_2">
										<ul class="right_menu"><li><a href="/jAnrkHM5">Untitled</a><span>1 sec ago</span></li><li><a href="/i0G5k7Hp">Untitled</a><span>7 sec ago</span></li><li><a href="/pMgexap2">Untitled</a><span>15 sec ago</span></li><li><a href="/49b8nGcn">Untitled</a><span>19 sec ago</span></li><li><a href="/7vnYqe5j">Untitled</a><span>20 sec ago</span></li><li><a href="/PThLT4DV">Untitled</a><span>24 sec ago</span></li><li><a href="/wNcw4bDK">Untitled</a><span>29 sec ago</span></li><li><a href="/P6NFGye8">packed</a><span>Lua | 32 sec ago</span></li></ul></div></div>										
				<div style="padding: 0; width:300px;height:260px;clear:left;">
					<iframe src="/adserver/300x250_tribal_safe.html" width="300" height="250" scrolling="no" frameborder="0" name="ad3"></iframe>
				</div>					<div id="steadfast" title="Pastebin is proudly hosted by Steadfast.net" onclick="location.href='http://steadfast.net/'"></div>
				</div>
				<div id="content_left">

	<div class="paste_box_frame">
		<div class="tweet">
			<div onclick="facebookpopup('/zHrhU6yF'); return false;" id="b_facebook2"><span id="b_facebook"></span></div>
			<div onclick="twitpopup('/zHrhU6yF'); return false;" id="b_twitter2"><span id="b_twitter"></span></div>
		</div>
		<div class="paste_box_icon">
			<img src="/i/t.gif" class="i_gb" alt="Guest" border="0" />	
		</div>
		<div class="paste_box_info">
			<div class="paste_box_line1" title="Untitled"><img src="/i/t.gif"  class="i_p0" width="16" height="16" title="Public paste, everybody can see this paste." alt=""  border="0" /><h1>Untitled</h1> </div>
			<div class="paste_box_line2">By: a guest  on <span title="Thursday 10th of March 2011 05:02:31 PM CDT" style="cursor:help">Mar 10th, 2011</span> &nbsp;|&nbsp; syntax: <a href="/archive/text">None</a> &nbsp;|&nbsp; size: 57.78 KB &nbsp;|&nbsp; hits: 97 &nbsp;|&nbsp; expires: Never</div>
			<div class="paste_box_line3"><a href="/download.php?i=zHrhU6yF" rel="nofollow">download</a> &nbsp;|&nbsp; <a href="/raw.php?i=zHrhU6yF" target="_blank" rel="nofollow">raw</a> &nbsp;|&nbsp; <a href="/embed.php?i=zHrhU6yF" rel="nofollow">embed</a> &nbsp;|&nbsp; <a href="/report.php?i=zHrhU6yF" rel="nofollow">report abuse</a> &nbsp;|&nbsp; <a href="/print.php?i=zHrhU6yF" rel="nofollow">print</a></div>
		</div>
	</div>
	
				<div class="banner_728">
					<iframe src="/adserver/728x90_tribal_safe.html" width="728" height="90" scrolling="no" frameborder="0" name="ad2"></iframe>
				</div>
				<div class="layout_clear"></div><div id="code_frame2">
	<div id="code_frame">
		<div id="code_buttons">
		
		<a href="javascript:togglev();" title="Show/Hide line numbers"><img src="/i/t.gif" border="0" alt="" class="i16 line" /></a> 
		<a href="javascript:togglew('text');" title="Toggle text wrapping"><img src="/i/t.gif" border="0" alt="" class="i16 wrap" /></a> 
		<a href="#" class="copyme" onclick="selectText('selectable');showdiv('copied');" title="Copy text to clipboard"><img src="/i/t.gif" border="0" alt="" class="i16 clipboard" /></a> <span id="copied">Text below is selected. Please press Ctrl+C to copy to your clipboard. (&#8984;+C on Mac)</span>

		</div>
		<div id="selectable">		
		<div class="text"><ol><li class="li1"><div class="de1">011-03-11 00:15:09,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted block blk_354714208243161006_11992 at file /data1/hadoop/dfs/data/current/blk_354714208243161006</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:09,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted block blk_5882884319791571381_11987 at file /data1/hadoop/dfs/data/current/blk_5882884319791571381</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:32,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_899853719635815095_12590 java.io.IOException: Connection reset by peer</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:32,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_899853719635815095_12590 Interrupted.</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:32,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_899853719635815095_12590 terminating</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:32,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_899853719635815095_12590 received exception java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:32,333 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver</div></li>
<li class="li2"><div class="de2">java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.read0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.read(IOUtil.java:175)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedInputStream.read(BufferedInputStream.java:317)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.read(DataInputStream.java:132)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:267)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:357)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:378)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020): Exception writing block blk_-3361345630416441624_12594 to mirror 192.168.2.28:50010</div></li>
<li class="li2"><div class="de2">java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.write(DataOutputStream.java:90)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:407)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-3361345630416441624_12594 2 Exception java.io.EOFException</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:180)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.readLong(DataInputStream.java:399)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:120)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:894)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_-3361345630416441624_12594 java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-3361345630416441624_12594 2 : Thread is interrupted.</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_-3361345630416441624_12594 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_-3361345630416441624_12594 received exception java.io.IOException: Connection reset by peer</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,353 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver</div></li>
<li class="li1"><div class="de1">java.io.IOException: Connection reset by peer</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.read0(Native Method)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.read(IOUtil.java:175)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedInputStream.read(BufferedInputStream.java:317)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.read(DataInputStream.java:132)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:267)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:314)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:378)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020): Exception writing block blk_-5458987145035540141_12591 to mirror 192.168.2.28:50010</div></li>
<li class="li1"><div class="de1">java.io.IOException: Broken pipe</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.write(DataOutputStream.java:90)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:407)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.read0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.read(IOUtil.java:175)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:178)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.readLong(DataInputStream.java:399)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:120)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:894)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_-3361345630416441624_12594, targets=[192.168.2.27:50010, 192.168.2.29:50010])</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,391 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li2"><div class="de2">java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,392 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_-5458987145035540141_12591 java.io.EOFException: while trying to read 49362 bytes</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_-5458987145035540141_12591, targets=[192.168.2.27:50010, 192.168.2.30:50010])</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_-5458987145035540141_12591 received exception java.io.IOException: Interrupted receiveBlock</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,397 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver</div></li>
<li class="li1"><div class="de1">java.io.IOException: Interrupted receiveBlock</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:579)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: Connection reset by peer</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_-3361345630416441624_12594(length=19937894), newblock=blk_-3361345630416441624_12597(length=19185534), datanode=192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_899853719635815095_12590, targets=[192.168.2.29:50010, 192.168.2.27:50010])</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_-5458987145035540141_12591(length=12094464), newblock=blk_-5458987145035540141_12599(length=11184128), datanode=192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-3361345630416441624_12597 src: /192.168.2.27:37735 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_-3361345630416441624_12597</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_899853719635815095_12590(length=14500352), newblock=blk_899853719635815095_12600(length=14500352), datanode=192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-5458987145035540141_12599 src: /192.168.2.27:37738 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_-5458987145035540141_12599</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37717, bytes: 12753456, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 54454272, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8087192685784189298_12281, duration: 34918783416</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:33,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_899853719635815095_12600 src: /192.168.2.29:42398 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:33,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_899853719635815095_12600</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:34,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37738, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-5458987145035540141_12599, duration: 1113483127</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:34,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_-5458987145035540141_12599 terminating</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:34,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_2666877984914128451_12601 src: /192.168.2.27:37741 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:35,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.29:42398, dest: /192.168.2.27:50010, bytes: 31943144, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-3,60020,1299794124568_1299794166934, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_899853719635815095_12600, duration: 2011247450</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:35,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_899853719635815095_12600 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:35,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_-8889207388813731787_12106, targets=[192.168.2.29:50010, 192.168.2.28:50010, 192.168.2.27:50010])</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:35,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.29:34956, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-3,60020,1299794124568_1299794166934, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_6530617834055356315_12587, duration: 37829298733</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:35,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_6530617834055356315_12587 terminating</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:36,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 0 time(s).</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:37,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 1 time(s).</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:38,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-6180665933974473989_12598 src: /192.168.2.29:42410 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:38,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received block blk_-6180665933974473989_12598 src: /192.168.2.29:42410 dest: /192.168.2.27:50010 of size 7226634</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:38,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 2 time(s).</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_5710097767500733988_12560 java.io.IOException: Connection reset by peer</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_5710097767500733988_12560 1 : Thread is interrupted.</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_5710097767500733988_12560 terminating</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_5710097767500733988_12560 received exception java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:39,070 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver</div></li>
<li class="li2"><div class="de2">java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.read0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.read(IOUtil.java:175)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedInputStream.read(BufferedInputStream.java:317)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.read(DataInputStream.java:132)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:267)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:314)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:378)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:39,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_899853719635815095_12600 to 192.168.2.30:50010 </div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:39,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 3 time(s).</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:39,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):Transmitted block blk_899853719635815095_12600 to /192.168.2.30:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:40,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 4 time(s).</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:41,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 5 time(s).</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:42,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 6 time(s).</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:43,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 7 time(s).</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:44,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-9102640389583079225_12603 src: /192.168.2.28:57263 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:44,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-2984387863588922353_12603 src: /192.168.2.30:50778 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:44,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 8 time(s).</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:44,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_-8889207388813731787_12106(length=34052806), newblock=blk_-8889207388813731787_12605(length=34052806), datanode=192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:44,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-8889207388813731787_12605 src: /192.168.2.28:57266 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:44,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen Block for append blk_-8889207388813731787_12605</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:45,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: setBlockPosition trying to set position to 34052806 for block blk_-8889207388813731787_12605 which is not a multiple of bytesPerChecksum 512</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:45,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: computePartialChunkCrc sizePartialChunk 198 block blk_-8889207388813731787_12605 offset in block 34052608 offset in metafile 266043</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:45,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Read in partial CRC chunk from disk for block blk_-8889207388813731787_12605</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:45,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.28:57266, dest: /192.168.2.27:50010, bytes: 34052806, op: HDFS_WRITE, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8889207388813731787_12605, duration: 20895505</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:45,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_-8889207388813731787_12605 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:47,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.26:54988, bytes: 34318846, op: HDFS_READ, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8889207388813731787_12605, duration: 481091810</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:48,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-9116162291337769777_12586 to 192.168.2.30:50010 </div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:48,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37735, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-3361345630416441624_12597, duration: 15397838575</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:48,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_-3361345630416441624_12597 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:48,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_7929231913190583369_12606 src: /192.168.2.27:37757 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:50,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):Transmitted block blk_-9116162291337769777_12586 to /192.168.2.30:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:50,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37741, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_2666877984914128451_12601, duration: 6410687851</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:50,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_2666877984914128451_12601 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:50,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-8643913463468935206_12606 src: /192.168.2.27:37759 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:51,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_7016095083901025726_12608 src: /192.168.2.26:54992 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:51,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-9187989681624368572_12609 src: /192.168.2.30:50788 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:51,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37740, bytes: 67633152, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-1975378591182157248_12284, duration: 17992018852</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:54,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_4312869116985736160_12202, targets=[192.168.2.27:50010, 192.168.2.29:50010, 192.168.2.28:50010])</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:54,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_4312869116985736160_12202(length=19231788), newblock=blk_4312869116985736160_12610(length=19231788), datanode=192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:54,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_4312869116985736160_12610 src: /192.168.2.26:54996 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:54,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen Block for append blk_4312869116985736160_12610</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,896 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li2"><div class="de2">java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,897 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_8215300540811877231_12595, targets=[192.168.2.27:50010, 192.168.2.30:50010])</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020): Exception writing block blk_8215300540811877231_12595 to mirror 192.168.2.30:50010</div></li>
<li class="li1"><div class="de1">java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.2.27:51759 remote=/192.168.2.30:50010]. 490000 millis timeout left.</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.write(DataOutputStream.java:90)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:407)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_8215300540811877231_12595 java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.2.27:51759 remote=/192.168.2.30:50010]. 490000 millis timeout left.</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: Connection reset by peer</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.FileDispatcher.write0(Native Method)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.IOUtil.write(IOUtil.java:43)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,902 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,902 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,905 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_8215300540811877231_12595 received exception java.io.IOException: Interrupted receiveBlock</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,906 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,906 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver</div></li>
<li class="li2"><div class="de2">java.io.IOException: Interrupted receiveBlock</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:579)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.EOFException</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.readFully(DataInputStream.java:180)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataInputStream.readLong(DataInputStream.java:399)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:120)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:894)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">&nbsp;</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li2"><div class="de2">java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_8215300540811877231_12595(length=11119104), newblock=blk_8215300540811877231_12611(length=11119104), datanode=192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,914 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,914 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,918 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,918 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,921 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,921 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: </div></li>
<li class="li1"><div class="de1">java.io.IOException: The stream is closed</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.io.DataOutputStream.flush(DataOutputStream.java:106)</div></li>
<li class="li1"><div class="de1">&nbsp; &nbsp; &nbsp; &nbsp; at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)</div></li>
<li class="li2"><div class="de2">&nbsp; &nbsp; &nbsp; &nbsp; at java.lang.Thread.run(Thread.java:662)</div></li>
<li class="li1"><div class="de1">&nbsp;</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:55,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_8215300540811877231_12611 src: /192.168.2.27:37766 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:55,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_8215300540811877231_12611</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:56,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37759, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8643913463468935206_12606, duration: 5120465819</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:56,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_-8643913463468935206_12606 terminating</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:56,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_8844898878465206844_12611 src: /192.168.2.27:37768 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:57,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37757, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_7929231913190583369_12606, duration: 8336528629</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:57,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_7929231913190583369_12606 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:57,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-3471476733074912555_12611 src: /192.168.2.27:37770 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:57,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37766, dest: /192.168.2.27:50010, bytes: 31016933, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_8215300540811877231_12611, duration: 1767092332</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:57,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_8215300540811877231_12611 terminating</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:57,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: setBlockPosition trying to set position to 19231788 for block blk_4312869116985736160_12610 which is not a multiple of bytesPerChecksum 512</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:57,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: computePartialChunkCrc sizePartialChunk 44 block blk_4312869116985736160_12610 offset in block 19231744 offset in metafile 150255</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:57,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Read in partial CRC chunk from disk for block blk_4312869116985736160_12610</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:57,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37772, bytes: 489, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 31016448, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_8215300540811877231_12611, duration: 153329</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:57,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37773, bytes: 24741, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 30992384, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_8215300540811877231_12611, duration: 192706</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:57,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.26:54996, dest: /192.168.2.27:50010, bytes: 19231788, op: HDFS_WRITE, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_4312869116985736160_12610, duration: 27929793</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:57,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_4312869116985736160_12610 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:58,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37770, dest: /192.168.2.27:50010, bytes: 4378354, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-3471476733074912555_12611, duration: 1414689904</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:58,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_-3471476733074912555_12611 terminating</div></li>
<li class="li1"><div class="de1">2011-03-11 00:15:58,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_7424820659162889773_12612 src: /192.168.2.27:37774 dest: /192.168.2.27:50010</div></li>
<li class="li2"><div class="de2">2011-03-11 00:15:58,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_55418405069629053_12613 src: /192.168.2.27:37776 dest: /192.168.2.27:50010</div></li>
<li class="li1"><div class="de1">2011-03-11 00:16:02,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.26:54998, bytes: 19382040, op: HDFS_READ, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_4312869116985736160_12610, duration: 370523255</div></li>
<li class="li2"><div class="de2">2011-03-11 00:16:02,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_9114403477479411144_12214, targets=[192.168.2.30:50010, 192.</div></li>
</ol></div>
		</div>
	</div></div>
	<div class="content_title">
		<span class="span_right raw_links"><a href="/index/zHrhU6yF" rel="nofollow">create a <u>new version</u> of this paste</a></span>
		RAW Paste Data
	</div>
	<form class="paste_form" id="myform" method="post" action="/post.php">
		<div class="textarea_border">
			<textarea id="paste_code" class="paste_code" name="paste_code" onkeydown="return catchTab(this,event)">011-03-11 00:15:09,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted block blk_354714208243161006_11992 at file /data1/hadoop/dfs/data/current/blk_354714208243161006
2011-03-11 00:15:09,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted block blk_5882884319791571381_11987 at file /data1/hadoop/dfs/data/current/blk_5882884319791571381
2011-03-11 00:15:32,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_899853719635815095_12590 java.io.IOException: Connection reset by peer
2011-03-11 00:15:32,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_899853719635815095_12590 Interrupted.
2011-03-11 00:15:32,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_899853719635815095_12590 terminating
2011-03-11 00:15:32,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_899853719635815095_12590 received exception java.io.IOException: Connection reset by peer
2011-03-11 00:15:32,333 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)
	at sun.nio.ch.IOUtil.read(IOUtil.java:175)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
	at java.io.DataInputStream.read(DataInputStream.java:132)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:267)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:357)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:378)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)
2011-03-11 00:15:33,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020): Exception writing block blk_-3361345630416441624_12594 to mirror 192.168.2.28:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)
	at java.io.DataOutputStream.write(DataOutputStream.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:407)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)

2011-03-11 00:15:33,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-3361345630416441624_12594 2 Exception java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:120)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:894)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:33,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_-3361345630416441624_12594 java.io.IOException: Connection reset by peer
2011-03-11 00:15:33,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-3361345630416441624_12594 2 : Thread is interrupted.
2011-03-11 00:15:33,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_-3361345630416441624_12594 terminating
2011-03-11 00:15:33,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_-3361345630416441624_12594 received exception java.io.IOException: Connection reset by peer
2011-03-11 00:15:33,353 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)
	at sun.nio.ch.IOUtil.read(IOUtil.java:175)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
	at java.io.DataInputStream.read(DataInputStream.java:132)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:267)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:314)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:378)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)
2011-03-11 00:15:33,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020): Exception writing block blk_-5458987145035540141_12591 to mirror 192.168.2.28:50010
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)
	at java.io.DataOutputStream.write(DataOutputStream.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:407)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)

2011-03-11 00:15:33,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)
	at sun.nio.ch.IOUtil.read(IOUtil.java:175)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:120)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:894)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:33,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_-3361345630416441624_12594, targets=[192.168.2.27:50010, 192.168.2.29:50010])
2011-03-11 00:15:33,391 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,392 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_-5458987145035540141_12591 java.io.EOFException: while trying to read 49362 bytes
2011-03-11 00:15:33,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_-5458987145035540141_12591, targets=[192.168.2.27:50010, 192.168.2.30:50010])
2011-03-11 00:15:33,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_-5458987145035540141_12591 received exception java.io.IOException: Interrupted receiveBlock
2011-03-11 00:15:33,397 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver
java.io.IOException: Interrupted receiveBlock
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:579)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)
2011-03-11 00:15:33,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:33,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:33,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_-3361345630416441624_12594(length=19937894), newblock=blk_-3361345630416441624_12597(length=19185534), datanode=192.168.2.27:50010
2011-03-11 00:15:33,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_899853719635815095_12590, targets=[192.168.2.29:50010, 192.168.2.27:50010])
2011-03-11 00:15:33,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:33,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:33,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,409 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:33,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_-5458987145035540141_12591 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:33,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_-5458987145035540141_12591(length=12094464), newblock=blk_-5458987145035540141_12599(length=11184128), datanode=192.168.2.27:50010
2011-03-11 00:15:33,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-3361345630416441624_12597 src: /192.168.2.27:37735 dest: /192.168.2.27:50010
2011-03-11 00:15:33,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_-3361345630416441624_12597
2011-03-11 00:15:33,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_899853719635815095_12590(length=14500352), newblock=blk_899853719635815095_12600(length=14500352), datanode=192.168.2.27:50010
2011-03-11 00:15:33,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-5458987145035540141_12599 src: /192.168.2.27:37738 dest: /192.168.2.27:50010
2011-03-11 00:15:33,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_-5458987145035540141_12599
2011-03-11 00:15:33,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37717, bytes: 12753456, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 54454272, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8087192685784189298_12281, duration: 34918783416
2011-03-11 00:15:33,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_899853719635815095_12600 src: /192.168.2.29:42398 dest: /192.168.2.27:50010
2011-03-11 00:15:33,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_899853719635815095_12600
2011-03-11 00:15:34,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37738, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-5458987145035540141_12599, duration: 1113483127
2011-03-11 00:15:34,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_-5458987145035540141_12599 terminating
2011-03-11 00:15:34,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_2666877984914128451_12601 src: /192.168.2.27:37741 dest: /192.168.2.27:50010
2011-03-11 00:15:35,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.29:42398, dest: /192.168.2.27:50010, bytes: 31943144, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-3,60020,1299794124568_1299794166934, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_899853719635815095_12600, duration: 2011247450
2011-03-11 00:15:35,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_899853719635815095_12600 terminating
2011-03-11 00:15:35,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_-8889207388813731787_12106, targets=[192.168.2.29:50010, 192.168.2.28:50010, 192.168.2.27:50010])
2011-03-11 00:15:35,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.29:34956, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-3,60020,1299794124568_1299794166934, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_6530617834055356315_12587, duration: 37829298733
2011-03-11 00:15:35,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_6530617834055356315_12587 terminating
2011-03-11 00:15:36,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 0 time(s).
2011-03-11 00:15:37,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 1 time(s).
2011-03-11 00:15:38,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-6180665933974473989_12598 src: /192.168.2.29:42410 dest: /192.168.2.27:50010
2011-03-11 00:15:38,260 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Received block blk_-6180665933974473989_12598 src: /192.168.2.29:42410 dest: /192.168.2.27:50010 of size 7226634
2011-03-11 00:15:38,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 2 time(s).
2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_5710097767500733988_12560 java.io.IOException: Connection reset by peer
2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_5710097767500733988_12560 1 : Thread is interrupted.
2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_5710097767500733988_12560 terminating
2011-03-11 00:15:39,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_5710097767500733988_12560 received exception java.io.IOException: Connection reset by peer
2011-03-11 00:15:39,070 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:202)
	at sun.nio.ch.IOUtil.read(IOUtil.java:175)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:243)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
	at java.io.DataInputStream.read(DataInputStream.java:132)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readToBuf(BlockReceiver.java:267)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket(BlockReceiver.java:314)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:378)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)
2011-03-11 00:15:39,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_899853719635815095_12600 to 192.168.2.30:50010 
2011-03-11 00:15:39,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 3 time(s).
2011-03-11 00:15:39,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):Transmitted block blk_899853719635815095_12600 to /192.168.2.30:50010
2011-03-11 00:15:40,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 4 time(s).
2011-03-11 00:15:41,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 5 time(s).
2011-03-11 00:15:42,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 6 time(s).
2011-03-11 00:15:43,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 7 time(s).
2011-03-11 00:15:44,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-9102640389583079225_12603 src: /192.168.2.28:57263 dest: /192.168.2.27:50010
2011-03-11 00:15:44,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-2984387863588922353_12603 src: /192.168.2.30:50778 dest: /192.168.2.27:50010
2011-03-11 00:15:44,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /192.168.2.28:50020. Already tried 8 time(s).
2011-03-11 00:15:44,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_-8889207388813731787_12106(length=34052806), newblock=blk_-8889207388813731787_12605(length=34052806), datanode=192.168.2.27:50010
2011-03-11 00:15:44,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-8889207388813731787_12605 src: /192.168.2.28:57266 dest: /192.168.2.27:50010
2011-03-11 00:15:44,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen Block for append blk_-8889207388813731787_12605
2011-03-11 00:15:45,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: setBlockPosition trying to set position to 34052806 for block blk_-8889207388813731787_12605 which is not a multiple of bytesPerChecksum 512
2011-03-11 00:15:45,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: computePartialChunkCrc sizePartialChunk 198 block blk_-8889207388813731787_12605 offset in block 34052608 offset in metafile 266043
2011-03-11 00:15:45,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Read in partial CRC chunk from disk for block blk_-8889207388813731787_12605
2011-03-11 00:15:45,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.28:57266, dest: /192.168.2.27:50010, bytes: 34052806, op: HDFS_WRITE, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8889207388813731787_12605, duration: 20895505
2011-03-11 00:15:45,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for block blk_-8889207388813731787_12605 terminating
2011-03-11 00:15:47,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.26:54988, bytes: 34318846, op: HDFS_READ, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8889207388813731787_12605, duration: 481091810
2011-03-11 00:15:48,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-9116162291337769777_12586 to 192.168.2.30:50010 
2011-03-11 00:15:48,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37735, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-3361345630416441624_12597, duration: 15397838575
2011-03-11 00:15:48,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_-3361345630416441624_12597 terminating
2011-03-11 00:15:48,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_7929231913190583369_12606 src: /192.168.2.27:37757 dest: /192.168.2.27:50010
2011-03-11 00:15:50,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):Transmitted block blk_-9116162291337769777_12586 to /192.168.2.30:50010
2011-03-11 00:15:50,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37741, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_2666877984914128451_12601, duration: 6410687851
2011-03-11 00:15:50,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_2666877984914128451_12601 terminating
2011-03-11 00:15:50,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-8643913463468935206_12606 src: /192.168.2.27:37759 dest: /192.168.2.27:50010
2011-03-11 00:15:51,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_7016095083901025726_12608 src: /192.168.2.26:54992 dest: /192.168.2.27:50010
2011-03-11 00:15:51,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-9187989681624368572_12609 src: /192.168.2.30:50788 dest: /192.168.2.27:50010
2011-03-11 00:15:51,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37740, bytes: 67633152, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-1975378591182157248_12284, duration: 17992018852
2011-03-11 00:15:54,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_4312869116985736160_12202, targets=[192.168.2.27:50010, 192.168.2.29:50010, 192.168.2.28:50010])
2011-03-11 00:15:54,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_4312869116985736160_12202(length=19231788), newblock=blk_4312869116985736160_12610(length=19231788), datanode=192.168.2.27:50010
2011-03-11 00:15:54,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_4312869116985736160_12610 src: /192.168.2.26:54996 dest: /192.168.2.27:50010
2011-03-11 00:15:54,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen Block for append blk_4312869116985736160_12610
2011-03-11 00:15:55,896 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,897 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_8215300540811877231_12595, targets=[192.168.2.27:50010, 192.168.2.30:50010])
2011-03-11 00:15:55,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020): Exception writing block blk_8215300540811877231_12595 to mirror 192.168.2.30:50010
java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.2.27:51759 remote=/192.168.2.30:50010]. 490000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:349)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)
	at java.io.DataOutputStream.write(DataOutputStream.java:90)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:407)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:534)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)

2011-03-11 00:15:55,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in receiveBlock for block blk_8215300540811877231_12595 java.io.InterruptedIOException: Interruped while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/192.168.2.27:51759 remote=/192.168.2.30:50010]. 490000 millis timeout left.
2011-03-11 00:15:55,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcher.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:72)
	at sun.nio.ch.IOUtil.write(IOUtil.java:43)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:334)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,902 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,902 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,905 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,906 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: writeBlock blk_8215300540811877231_12595 received exception java.io.IOException: Interrupted receiveBlock
2011-03-11 00:15:55,906 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,906 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(192.168.2.27:50010, storageID=DS-1292519212-192.168.2.27-50010-1299580340977, infoPort=50075, ipcPort=50020):DataXceiver
java.io.IOException: Interrupted receiveBlock
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:579)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:417)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:122)
2011-03-11 00:15:55,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readLong(DataInputStream.java:399)
	at org.apache.hadoop.hdfs.protocol.DataTransferProtocol$PipelineAck.readFields(DataTransferProtocol.java:120)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:894)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: oldblock=blk_8215300540811877231_12595(length=11119104), newblock=blk_8215300540811877231_12611(length=11119104), datanode=192.168.2.27:50010
2011-03-11 00:15:55,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,914 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,914 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,918 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,918 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,921 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in BlockReceiver.run(): 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,921 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: checkDiskError: exception: 
java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)
2011-03-11 00:15:55,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder blk_8215300540811877231_12595 2 Exception java.io.IOException: The stream is closed
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:108)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1004)
	at java.lang.Thread.run(Thread.java:662)

2011-03-11 00:15:55,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_8215300540811877231_12611 src: /192.168.2.27:37766 dest: /192.168.2.27:50010
2011-03-11 00:15:55,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Reopen already-open Block for append blk_8215300540811877231_12611
2011-03-11 00:15:56,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37759, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-8643913463468935206_12606, duration: 5120465819
2011-03-11 00:15:56,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_-8643913463468935206_12606 terminating
2011-03-11 00:15:56,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_8844898878465206844_12611 src: /192.168.2.27:37768 dest: /192.168.2.27:50010
2011-03-11 00:15:57,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37757, dest: /192.168.2.27:50010, bytes: 67108864, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_7929231913190583369_12606, duration: 8336528629
2011-03-11 00:15:57,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_7929231913190583369_12606 terminating
2011-03-11 00:15:57,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_-3471476733074912555_12611 src: /192.168.2.27:37770 dest: /192.168.2.27:50010
2011-03-11 00:15:57,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37766, dest: /192.168.2.27:50010, bytes: 31016933, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_8215300540811877231_12611, duration: 1767092332
2011-03-11 00:15:57,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 1 for block blk_8215300540811877231_12611 terminating
2011-03-11 00:15:57,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: setBlockPosition trying to set position to 19231788 for block blk_4312869116985736160_12610 which is not a multiple of bytesPerChecksum 512
2011-03-11 00:15:57,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: computePartialChunkCrc sizePartialChunk 44 block blk_4312869116985736160_12610 offset in block 19231744 offset in metafile 150255
2011-03-11 00:15:57,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Read in partial CRC chunk from disk for block blk_4312869116985736160_12610
2011-03-11 00:15:57,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37772, bytes: 489, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 31016448, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_8215300540811877231_12611, duration: 153329
2011-03-11 00:15:57,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.27:37773, bytes: 24741, op: HDFS_READ, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 30992384, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_8215300540811877231_12611, duration: 192706
2011-03-11 00:15:57,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.26:54996, dest: /192.168.2.27:50010, bytes: 19231788, op: HDFS_WRITE, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_4312869116985736160_12610, duration: 27929793
2011-03-11 00:15:57,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_4312869116985736160_12610 terminating
2011-03-11 00:15:58,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:37770, dest: /192.168.2.27:50010, bytes: 4378354, op: HDFS_WRITE, cliID: DFSClient_hb_rs_iletken-test-1,60020,1299794103858_1299794167386, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_-3471476733074912555_12611, duration: 1414689904
2011-03-11 00:15:58,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 2 for block blk_-3471476733074912555_12611 terminating
2011-03-11 00:15:58,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_7424820659162889773_12612 src: /192.168.2.27:37774 dest: /192.168.2.27:50010
2011-03-11 00:15:58,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving block blk_55418405069629053_12613 src: /192.168.2.27:37776 dest: /192.168.2.27:50010
2011-03-11 00:16:02,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.2.27:50010, dest: /192.168.2.26:54998, bytes: 19382040, op: HDFS_READ, cliID: DFSClient_hb_m_iletken-test-0:60000_1299794080559, offset: 0, srvID: DS-1292519212-192.168.2.27-50010-1299580340977, blockid: blk_4312869116985736160_12610, duration: 370523255
2011-03-11 00:16:02,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Client calls recoverBlock(block=blk_9114403477479411144_12214, targets=[192.168.2.30:50010, 192.</textarea>
		</div>			
	</form>
	<script type="text/javascript" language="javascript">
	$(document).ready(function(){
	$('textarea').autoResize({minHeight: 80,maxHeight: 250});
	geturl = "http://pastebin.com/zHrhU6yF";
		$.getJSON("http://graph.facebook.com/fql?q=SELECT total_count FROM link_stat WHERE url='http://pastebin.com/zHrhU6yF'",
	function(data) {
	$('#b_facebook').append(data.data[0].total_count);
	}); 
	$.getJSON('http://urls.api.twitter.com/1/urls/count.json?url='+geturl+'&callback=?',
	function(data) {
	$('#b_twitter').append(data.count);
	});
	})
    </script>						<div style="margin:10px 0;clear:left"></div>
					</div>
					<div class="frame_spacer"><!-- --></div>
					<div id="footer_top" style="clear:both">	
						<div class="footer_top_title">Pastebin.com Tools &amp; Applications</div>
						<div class="footer_top_text">
							<img src="/i/t.gif" alt="" class="icon24 iphone" /><a href="/tools#iphone">iPhone/iPad</a>
							<img src="/i/t.gif" alt="" class="icon24 windows" /><a href="/tools#windows">Windows</a>
							<img src="/i/t.gif" alt="" class="icon24 firefox" /><a href="/tools#firefox">Firefox</a>
							<img src="/i/t.gif" alt="" class="icon24 chrome" /><a href="/tools#chrome">Chrome</a>
							<img src="/i/t.gif" alt="" class="icon24 webos" /><a href="/tools#webos">WebOS</a>
							<img src="/i/t.gif" alt="" class="icon24 android" /><a href="/tools#android">Android</a>
							<img src="/i/t.gif" alt="" class="icon24 macos" /><a href="/tools#macos">Mac</a>
							<img src="/i/t.gif" alt="" class="icon24 opera" /><a href="/tools#opera">Opera</a>
							<img src="/i/t.gif" alt="" class="icon24 clickto" /><a href="/tools#clickto">Click.to</a>
							<img src="/i/t.gif" alt="" class="icon24 unix" /><a href="/tools#pastebincl">UNIX</a>
							<img src="/i/t.gif" alt="" class="icon24 windowsphone" /><a href="/tools#windowsphone">WinPhone</a>
						</div>
					</div>
				</div>
			</div>
		</div>
		<div id="footer">
			<div id="logo_small"></div>
			<div id="footer_links">
				<a href="/">create new paste</a> &nbsp;|&nbsp; <a href="/api">api</a> &nbsp;|&nbsp; <a href="/trends">trends</a> &nbsp;|&nbsp; <a href="/users">users</a> &nbsp;|&nbsp; <a href="/faq">faq</a> &nbsp;|&nbsp; <a href="/tools">tools</a> &nbsp;|&nbsp; <a href="/privacy">privacy</a> &nbsp;|&nbsp; <a href="/cookies_policy">cookies policy</a> &nbsp;|&nbsp; <a href="/contact">contact</a> &nbsp;|&nbsp; <a href="/stats">stats</a> &nbsp;|&nbsp; <a href="/pro">go pro</a> 
				<br />Follow us: <a href="http://www.facebook.com/pages/Pastebincom/150549571626327" target="_blank">pastebin on facebook</a> &nbsp;|&nbsp; <a href="http://twitter.com/#!/pastebin" target="blank">pastebin on twitter</a> &nbsp;|&nbsp; <a href="https://www.google.com/search?gl=us&amp;pz=1&amp;cf=all&amp;ned=us&amp;hl=en&amp;tbm=nws&amp;as_oq=pastebin&amp;as_occt=any&amp;as_qdr=d&amp;authuser=0" target="_blank">pastebin in the news</a>
				<br />Dedicated <a href="http://steadfast.net/services/dedicated-servers.php" rel="nofollow" target="_blank">Server</a> Hosting by <a href="http://steadfast.net/" rel="nofollow" target="_blank">Steadfast</a><br />Pastebin v3.11 rendered in: 0.035 seconds				
			</div>
			<div id="footer_right">&nbsp;</div>
		</div>
		<script type="text/javascript">
		$('.narrow_it').click(function(){
		    $('#super_frame').animate({width:'100%'}, 500);
		    $('#footer').animate({width:'100%'}, 500);
			$(".narrow_it").hide();
			$(".wide_it").show();
			$.get('/layout.php', function(data) {
			});
		});
		$('.wide_it').click(function(){
		    $('#super_frame').animate({width:'1200px'}, 500);
		    $('#footer').animate({width:'1200px'}, 500);
			$(".wide_it").hide();
			$(".narrow_it").show();
			$.get('/layout.php', function(data) {
			});
		});
		</script>
	</body>
</html>
